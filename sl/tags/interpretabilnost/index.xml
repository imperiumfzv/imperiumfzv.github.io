<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Interpretabilnost | Slovensko</title>
    <link>/sl/tags/interpretabilnost/</link>
      <atom:link href="/sl/tags/interpretabilnost/index.xml" rel="self" type="application/rss+xml" />
    <description>Interpretabilnost</description>
    <generator>Source Themes Academic (https://sourcethemes.com/academic/)</generator><language>sl</language><copyright>UM FHS Research Institute©, 2020</copyright><lastBuildDate>Wed, 01 Apr 2020 00:00:00 +0000</lastBuildDate>
    <image>
      <url>/images/logo.svg</url>
      <title>Interpretabilnost</title>
      <link>/sl/tags/interpretabilnost/</link>
    </image>
    
    <item>
      <title>FWO-ARRS projekt</title>
      <link>/sl/project/fwo-arrs_2019-2022/</link>
      <pubDate>Wed, 01 Apr 2020 00:00:00 +0000</pubDate>
      <guid>/sl/project/fwo-arrs_2019-2022/</guid>
      <description>&lt;p&gt;&lt;strong&gt;Izboljšanje razumljivosti in napovedne zmogljivosti modelov za oceno tveganja in podporo odločanju v kliničnem okolju&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;sub&gt;Glavna institucija gostiteljica: KU Leuven&lt;br&gt;
Vodja: Katrien Verbert (KU Leuven, Odsek za informatiko)&lt;/sub&gt;&lt;/p&gt;
&lt;p&gt;&lt;sub&gt;Tuja institucija gostiteljica: Univerza v Mariboru&lt;br&gt;
Vodja: Gregor Stiglic (UM, Fakulteta za zdravstvene vede)&lt;/sub&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Povzetek&lt;/strong&gt;&lt;br&gt;
Nedavno ponovno odkrite in močno izboljšanih metod nevronskih mrežel, imenovane globoke nevronske mreže, postajajo vse bolj priljubljene kot napovedno orodje na različnih področjih zdravstva. Pokazalo se je, da globoke nevronske mreže večkrat presegajo manj zapletene modele napovedovanja, zlasti v primerih kjer je potreben inženiring spremenljivk. Po drugi strani pa ocena tveganja na podlagi globokih nevronskih mrež omogoča zelo omejeno interpretacijo dobljenih rezultatov s strani zdravstvenih strokovnjakov ali pacientov. Za reševanje tega izziva bo projekt raziskal vložitev modelov globokih nevronskih mrež in izvzem spremenljivk z metodami vizualne analitike. Vizualna analitika združuje avtomatizirano analizo z metodami vizualizacije, da bi dobili vpogled v zapletena podatkovja in interpretabilnost modelov. Natančneje bomo raziskali, kako lahko oblikujemo, razvijamo in ocenjujemo interaktivne tehnike vizualne analitike na podlagi različnih napovednih modelov za oceno tveganja pri kroničnih bolezni (T2D in CVD). Splošni cilj je dvojen:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;pojasniti napovedi in negotovost teh napovedi zdravstvenim strokovnjakom, ki bo služila kot podpora pri odločanju in povečanje zaupanja uporabnikov ter&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;vključitev vnosa in povratnih informacij končnih uporabnikov v postopek predvidevanja, kot so manjkajoče laboratorijske vrednosti in optimizacija parametrov. Pristop bo ovrednoten v dveh podrobnih študijah uporabnikov v kliničnih okoljih.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
</description>
    </item>
    
    <item>
      <title>Interpretability of machine learning based prediction models in healthcare</title>
      <link>/sl/publication/wires_2020/</link>
      <pubDate>Thu, 20 Feb 2020 00:00:00 +0000</pubDate>
      <guid>/sl/publication/wires_2020/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Local vs. global interpretability of machine learning models in type 2 diabetes mellitus screening</title>
      <link>/sl/publication/lncs_2019/</link>
      <pubDate>Fri, 03 Jan 2020 00:00:00 +0000</pubDate>
      <guid>/sl/publication/lncs_2019/</guid>
      <description></description>
    </item>
    
  </channel>
</rss>
